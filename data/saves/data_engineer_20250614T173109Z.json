{
  "job_id": "data_engineer_20250614T173109Z",
  "timestamp": "20250614T173109Z",
  "ctx": {
    "job_title": "data engineer",
    "context": "I want a candidate who had knowledge og python, SQL, ETL workflows, AWS GLue, Lambad, EC2. he shule have expereince in containerizing and deploying solution. Hew should have a masteres degree in CS or statistincs or similar fields. He should posses strong stakeholder communication and have team leadership qualities. Please make sure you follow industry standard. The candidate should have extensive expereince in the above skills in addition to general skillset of a data engineer\n\n\n\nSQL, Python, ETL, APCHE SPARK, HADOOP, Airflow, Data Modelling, Data Warehousing. Masters degree in Data Science or CS.\n\nThe candidate should have extensive expereince in the above skills in addition to general skillset of a data engineer",
    "years_exp": 3,
    "company_name": "DS Group",
    "job_type": "Full-Time",
    "job_location": "Boston,MA",
    "company_url": "https://www.dsgroup.com/"
  },
  "job_description": "### About the Company\n            At DS Group, we are more than just a company; we are a community driven by innovation, integrity, and inclusivity. With a rich heritage spanning over three decades, we specialize in creating high-quality products that enrich lives and foster connections. Our diverse team, united by a shared passion for excellence, thrives in a dynamic environment where every voice is valued. We believe that collaboration fuels creativity, and we celebrate the unique perspectives that each individual brings to the table. Committed to sustainability and social responsibility, we strive to make a positive impact on our communities and the environment. Join us on our journey to inspire, innovate, and elevate everyday experiences—together, we can make a difference. Welcome to DS Group, where your potential meets our purpose.\n\n            ### Job Description\n            ```markdown\n# Job Description: Data Engineer\n\n**Company Name:** DS Group  \n**Job Type:** Full-Time  \n**Job Location:** Boston, MA  \n\n## Responsibilities\n- Design, develop, and maintain robust ETL workflows to ensure efficient data processing.\n- Collaborate with stakeholders to gather requirements and translate them into technical specifications.\n- Implement data solutions using AWS services such as Glue, Lambda, and EC2.\n- Containerize and deploy data solutions to enhance scalability and maintainability.\n- Utilize Apache Spark and Hadoop for big data processing and analytics.\n- Perform data modeling and maintain data warehousing solutions.\n- Lead and mentor team members to foster a collaborative work environment.\n\n## Required Skills\n- Proficiency in Python and SQL for data manipulation and analysis.\n- Extensive experience with ETL workflows and data pipeline development.\n- Strong understanding of AWS services, particularly Glue, Lambda, and EC2.\n- Experience with containerization technologies for deploying data solutions.\n- Master’s degree in Computer Science, Statistics, or a related field.\n- Excellent stakeholder communication and team leadership qualities.\n- Minimum of 3 years of relevant experience in data engineering.\n\n## Preferred Skills\n- Familiarity with Apache Spark, Hadoop, Airflow, and data warehousing concepts.\n- Experience in data modeling techniques.\n\n## Benefits\n- Competitive salary and performance-based incentives.\n- Comprehensive health, dental, and vision insurance.\n- Opportunities for professional development and growth.\n- Flexible work environment and work-life balance initiatives.\n\nInterested candidates may send their resume to [career@dsgroup.com](mailto:career@dsgroup.com).\n```"
}