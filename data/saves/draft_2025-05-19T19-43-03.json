{
  "job_title": "data engineer",
  "context": "I want a candidate who had knowledge og python, SQL, ETL workflows, AWS GLue, Lambad, EC2. he shule have expereince in containerizing and deploying solution. Hew should have a masteres degree in CS or statistincs or similar fields. He should posses strong stakeholder communication and have team leadership qualities     ",
  "years_exp": "5",
  "draft_jd": "**Job Title: Data Engineer**\n\n**Responsibilities:**\n- Design, develop, and maintain scalable ETL workflows to support data integration and processing.\n- Collaborate with stakeholders to understand data requirements and deliver solutions that meet business needs.\n- Implement and manage data pipelines using AWS services such as Glue, Lambda, and EC2.\n- Containerize and deploy data solutions using modern containerization technologies.\n- Optimize data storage and retrieval processes to enhance performance and efficiency.\n- Lead and mentor junior team members, fostering a collaborative team environment.\n\n**Required Skills:**\n- Master\u2019s degree in Computer Science, Statistics, or a related field.\n- Minimum of 5 years of experience in data engineering or related roles.\n- Proficiency in Python and SQL for data manipulation and analysis.\n- Hands-on experience with AWS services, particularly Glue, Lambda, and EC2.\n- Strong understanding of ETL workflows and data pipeline architecture.\n- Excellent communication skills for effective stakeholder engagement.\n\n**Preferred Skills:**\n- Experience with containerization technologies (e.g., Docker, Kubernetes).\n- Familiarity with data warehousing solutions and big data technologies.\n- Knowledge of data governance and best practices in data management.\n\n**Benefits:**\n- Competitive salary and performance-based bonuses.\n- Comprehensive health, dental, and vision insurance.\n- Opportunities for professional development and continuous learning.\n- Flexible work hours and remote work options.\n- Collaborative and inclusive company culture."
}